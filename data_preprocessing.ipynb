{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, GlobalMaxPool1D\n",
    "from keras.layers import Bidirectional, Dropout\n",
    "\n",
    "# 1. Weak Supervision Labeling\n",
    "def weak_supervision_label(question):\n",
    "    if not isinstance(question, str):\n",
    "        return [0.33, 0.33, 0.33]  # Default uncertain label for non-string input\n",
    "\n",
    "    question = question.lower()\n",
    "    \n",
    "    # Define similar question words for each category\n",
    "    what_like = [\"what\", \"which\", \"who\", \"where\", \"when\"]\n",
    "    how_like = [\"how\", \"in what way\", \"by what means\"]\n",
    "    why_like = [\"why\", \"for what reason\", \"how come\"]\n",
    "    \n",
    "    # Initialize the label\n",
    "    label = np.array([0.0, 0.0, 0.0])\n",
    "    \n",
    "    # Define weights for the word position in the question\n",
    "    weight_start = 0.5\n",
    "    weight_middle = 1.0\n",
    "    weight_end = 2.0\n",
    "    \n",
    "    # Helper function to apply weights based on position\n",
    "    def apply_weights(word_list, weight):\n",
    "        nonlocal label\n",
    "        for word in word_list:\n",
    "            if word in question:\n",
    "                if question.endswith(word):\n",
    "                    label += np.array([weight_end if word in what_like else 0, \n",
    "                                        weight_end if word in how_like else 0, \n",
    "                                        weight_end if word in why_like else 0])\n",
    "                elif question.startswith(word):\n",
    "                    label += np.array([weight_start if word in what_like else 0, \n",
    "                                        weight_start if word in how_like else 0, \n",
    "                                        weight_start if word in why_like else 0])\n",
    "                else: \n",
    "                    label += np.array([weight_middle if word in what_like else 0, \n",
    "                                        weight_middle if word in how_like else 0, \n",
    "                                        weight_middle if word in why_like else 0])\n",
    "    \n",
    "    # Apply the weights for each category\n",
    "    apply_weights(what_like, weight_middle)\n",
    "    apply_weights(how_like, weight_middle)\n",
    "    apply_weights(why_like, weight_middle)\n",
    "    \n",
    "    # Normalize the label to sum to 1\n",
    "    if np.sum(label) > 0:\n",
    "        label /= np.sum(label)\n",
    "    else:\n",
    "        label = np.array([0.33, 0.33, 0.33])  # Uncertain label\n",
    "    \n",
    "    return label.tolist()\n",
    "\n",
    "# Example usage\n",
    "question = \"How does this work?\"\n",
    "print(weak_supervision_label(question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/yvlkqw5j5rz7d708gr4_bt6m0000gn/T/ipykernel_65419/513658210.py:1: DtypeWarning: Columns (7,8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_csv = pd.read_csv('/Users/lancesanterre/intern_2024/data/uncleaned/q_quora.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(404351,)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv = pd.read_csv('/Users/lancesanterre/intern_2024/data/uncleaned/q_quora.csv')\n",
    "data_csv['question1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('data/uncleaned/dev-v1.1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for entry in data[\"data\"]:\n",
    "    for paragraph in entry[\"paragraphs\"]:\n",
    "        for qa in paragraph[\"qas\"]:\n",
    "            questions.append(qa[\"question\"])\n",
    "for quest in data_csv['question1']:\n",
    "    questions.append(quest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(map(weak_supervision_label, questions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which NFL team won Super Bowl 50?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What color was used to emphasize the 50th anni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414916</th>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414917</th>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414918</th>\n",
       "      <td>What is one coin?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414919</th>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414920</th>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>414921 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Which NFL team represented the AFC at Super Bo...\n",
       "1       Which NFL team represented the NFC at Super Bo...\n",
       "2                     Where did Super Bowl 50 take place?\n",
       "3                       Which NFL team won Super Bowl 50?\n",
       "4       What color was used to emphasize the 50th anni...\n",
       "...                                                   ...\n",
       "414916  How many keywords are there in the Racket prog...\n",
       "414917          Do you believe there is life after death?\n",
       "414918                                  What is one coin?\n",
       "414919  What is the approx annual cost of living while...\n",
       "414920              What is like to have sex with cousin?\n",
       "\n",
       "[414921 rows x 1 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(questions)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where did Super Bowl 50 take place?</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which NFL team won Super Bowl 50?</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What color was used to emphasize the 50th anni...</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0           labels\n",
       "0  Which NFL team represented the AFC at Super Bo...  [1.0, 0.0, 0.0]\n",
       "1  Which NFL team represented the NFC at Super Bo...  [1.0, 0.0, 0.0]\n",
       "2                Where did Super Bowl 50 take place?  [1.0, 0.0, 0.0]\n",
       "3                  Which NFL team won Super Bowl 50?  [1.0, 0.0, 0.0]\n",
       "4  What color was used to emphasize the 50th anni...  [1.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.insert(1,'labels',labels)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(df):\n",
    "    # Convert the DataFrame to a NumPy array\n",
    "    data_array = df.to_numpy()\n",
    "\n",
    "    # Initialize lists to store rows based on the filter\n",
    "    equal_to_33 = []\n",
    "    not_equal_to_33 = []\n",
    "\n",
    "    # Iterate over the rows in the array\n",
    "    for row in data_array:\n",
    "        # Check the condition in the 'labels' column (assumed to be the last column)\n",
    "        labels = row[-1]  # Assuming 'labels' is the last column\n",
    "        if all(label == 0.33 for label in labels):\n",
    "            equal_to_33.append(row)\n",
    "        else:\n",
    "            not_equal_to_33.append(row)\n",
    "\n",
    "    # Convert the lists back to DataFrames\n",
    "    df_equal_to_33 = pd.DataFrame(equal_to_33, columns=df.columns)\n",
    "    df_not_equal_to_33 = pd.DataFrame(not_equal_to_33, columns=df.columns)\n",
    "\n",
    "    return df_equal_to_33, df_not_equal_to_33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsure, sure = filter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data.pkl', compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_questions = sure[0]\n",
    "filtered_labels = sure['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 347058 entries, 0 to 347057\n",
      "Series name: 0\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "347058 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 2.6+ MB\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 347058 entries, 0 to 347057\n",
      "Series name: labels\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "347058 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 2.6+ MB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "print(filtered_questions.info(),filtered_labels.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 147/8677\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:25\u001b[0m 17ms/step - accuracy: 0.7511 - loss: 1.1055"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[39m# 5. Model Training\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_test, y_test))\n\u001b[1;32m     31\u001b[0m \u001b[39m# 6. Evaluate Model Performance\u001b[39;00m\n\u001b[1;32m     32\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mfor\u001b[39;00m step, iterator \u001b[39min\u001b[39;00m epoch_iterator\u001b[39m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    315\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function\u001b[39m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m   \u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_flat(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[39m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[39m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(filtered_questions)\n",
    "sequences = tokenizer.texts_to_sequences(filtered_questions)\n",
    "X = pad_sequences(sequences, maxlen=10)\n",
    "\n",
    "# Convert labels to numpy array\n",
    "y = np.array(filtered_labels.tolist())  # Convert Series of lists to a NumPy array\n",
    "\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=10),\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    GlobalMaxPool1D(),\n",
    "    Dense(64, kernel_regularizer='l2', activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "# 3. Compile the Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 4. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 5. Model Training\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# 6. Evaluate Model Performance\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_questions = unsure[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo ambiguous questions found.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     ambiguous_sequences \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mtexts_to_sequences(ambiguous_questions)\n\u001b[1;32m      5\u001b[0m     ambiguous_X \u001b[39m=\u001b[39m pad_sequences(ambiguous_sequences, maxlen\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[39m# Perform prediction only if ambiguous_X is not empty\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/legacy/preprocessing/text.py:177\u001b[0m, in \u001b[0;36mTokenizer.texts_to_sequences\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtexts_to_sequences\u001b[39m(\u001b[39mself\u001b[39m, texts):\n\u001b[0;32m--> 177\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtexts_to_sequences_generator(texts))\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/legacy/preprocessing/text.py:192\u001b[0m, in \u001b[0;36mTokenizer.texts_to_sequences_generator\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manalyzer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m         seq \u001b[39m=\u001b[39m text_to_word_sequence(\n\u001b[1;32m    193\u001b[0m             text,\n\u001b[1;32m    194\u001b[0m             filters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters,\n\u001b[1;32m    195\u001b[0m             lower\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlower,\n\u001b[1;32m    196\u001b[0m             split\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit,\n\u001b[1;32m    197\u001b[0m         )\n\u001b[1;32m    198\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m         seq \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manalyzer(text)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/legacy/preprocessing/text.py:22\u001b[0m, in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39m\"\"\"DEPRECATED.\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[0;32m---> 22\u001b[0m     input_text \u001b[39m=\u001b[39m input_text\u001b[39m.\u001b[39mlower()\n\u001b[1;32m     24\u001b[0m translate_dict \u001b[39m=\u001b[39m {c: split \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m filters}\n\u001b[1;32m     25\u001b[0m translate_map \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mmaketrans(translate_dict)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "\n",
    "if len(ambiguous_questions) == 0:\n",
    "    print(\"No ambiguous questions found.\")\n",
    "else: \n",
    "    ambiguous_sequences = tokenizer.texts_to_sequences(ambiguous_questions)\n",
    "    ambiguous_X = pad_sequences(ambiguous_sequences, maxlen=10)\n",
    "\n",
    "    # Perform prediction only if ambiguous_X is not empty\n",
    "    if ambiguous_X.size > 0:\n",
    "        predictions = model.predict(ambiguous_X)\n",
    "        for question, prediction in zip(ambiguous_questions, predictions):\n",
    "            print(f\"Question: {question}\")\n",
    "            print(f\"Predicted Label: {np.round(prediction, 2)}\")\n",
    "    else:\n",
    "        print(\"No valid sequences for prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_question(question, tokenizer, maxlen=10):\n",
    "    # Tokenize the question\n",
    "    sequence = tokenizer.texts_to_sequences([question])\n",
    "    # Pad the sequence to ensure it has the correct length\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=maxlen)\n",
    "    return padded_sequence\n",
    "\n",
    "def predict_question(question, model, tokenizer, maxlen=10):\n",
    "    # Preprocess the question\n",
    "    processed_question = preprocess_question(question, tokenizer, maxlen)\n",
    "    # Predict the category\n",
    "    prediction = model.predict(processed_question)\n",
    "    # Return the prediction\n",
    "    return prediction\n",
    "\n",
    "# Example question\n",
    "example_question = \"Explain the process of photosynthesis in plants.\"\n",
    "prediction = predict_question(example_question, model, tokenizer)\n",
    "\n",
    "# Print the prediction\n",
    "print(np.round(prediction, 2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
